---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - .env.example
  - .gitignore
  - src/__init__.py
  - src/models/__init__.py
  - src/models/schemas.py
  - src/database/__init__.py
  - src/database/client.py
  - src/fetchers/__init__.py
  - supabase/migrations/00001_create_foundation_tables.sql
autonomous: true
user_setup:
  - service: supabase
    why: "Managed Postgres with realtime subscriptions"
    env_vars:
      - name: SUPABASE_URL
        source: "Supabase Dashboard -> Settings -> API -> Project URL"
      - name: SUPABASE_KEY
        source: "Supabase Dashboard -> Settings -> API -> anon/public key"
    dashboard_config:
      - task: "Create a new Supabase project"
        location: "https://supabase.com/dashboard -> New Project"
      - task: "Enable realtime replication for all tables after migration"
        location: "Supabase Dashboard -> Database -> Replication -> Enable for each table"
      - task: "Set REPLICA IDENTITY FULL on all tables"
        location: "Run in SQL Editor: ALTER TABLE tablename REPLICA IDENTITY FULL; for each table"

must_haves:
  truths:
    - "Python project installs with all dependencies via pip"
    - "Supabase migration SQL creates all 7 tables when applied"
    - "Pydantic models validate data for all table schemas"
    - "Async Supabase client connects and can perform basic CRUD"
  artifacts:
    - path: "pyproject.toml"
      provides: "Project metadata and all dependencies"
      contains: "supabase"
    - path: "supabase/migrations/00001_create_foundation_tables.sql"
      provides: "All 7 table definitions with realtime publication"
      contains: "CREATE TABLE"
    - path: "src/models/schemas.py"
      provides: "Pydantic models for all tables"
      contains: "class Article"
    - path: "src/database/client.py"
      provides: "Async Supabase singleton client"
      contains: "acreate_client"
  key_links:
    - from: "src/database/client.py"
      to: "supabase"
      via: "acreate_client from supabase package"
      pattern: "from supabase import acreate_client"
    - from: "src/models/schemas.py"
      to: "supabase/migrations/00001_create_foundation_tables.sql"
      via: "Pydantic fields match SQL columns"
      pattern: "class Article|class SocialPost|class VesselPosition"
---

<objective>
Scaffold the Dragon Watch Python project with all dependencies, create the Supabase database schema (7 tables with realtime), define Pydantic validation models for all data types, and build the async Supabase client singleton.

Purpose: Every fetcher, the FastAPI app, and the demo data loader depend on the project structure, database schema, models, and client. This must exist first.
Output: Installable Python project, SQL migration file, Pydantic models, async DB client.
</objective>

<execution_context>
@/Users/gremmy/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gremmy/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Project scaffolding and Supabase schema migration</name>
  <files>
    pyproject.toml
    .env.example
    .gitignore
    src/__init__.py
    src/models/__init__.py
    src/database/__init__.py
    src/fetchers/__init__.py
    supabase/migrations/00001_create_foundation_tables.sql
  </files>
  <action>
    Create the Python project structure and database schema.

    1. Create `pyproject.toml` with:
       - Project name: dragon-watch
       - Python requires: >=3.11
       - Dependencies: supabase>=2.27.3, fastapi, uvicorn[standard], gdeltdoc>=1.12.0, Telethon>=1.42.0, websockets>=16.0, pydantic>=2.0, pandas, python-dotenv
       - Dev dependencies: pytest, pytest-asyncio

    2. Create `.env.example` with placeholder keys:
       - SUPABASE_URL=your-project-url
       - SUPABASE_KEY=your-anon-key
       - TELEGRAM_API_ID=your-api-id
       - TELEGRAM_API_HASH=your-api-hash
       - AISSTREAM_API_KEY=your-api-key

    3. Create `.gitignore` with Python defaults plus:
       - .env
       - *.session (Telethon session files)
       - __pycache__/
       - .venv/
       - *.pyc

    4. Create empty `__init__.py` files for: src/, src/models/, src/database/, src/fetchers/

    5. Create `supabase/migrations/00001_create_foundation_tables.sql` with ALL 7 tables:
       - articles: id BIGSERIAL PK, url TEXT UNIQUE NOT NULL, title TEXT NOT NULL, domain TEXT NOT NULL, published_at TIMESTAMPTZ NOT NULL, tone_score FLOAT, language TEXT, source_country TEXT, raw_data JSONB, created_at TIMESTAMPTZ DEFAULT NOW()
       - social_posts: id BIGSERIAL PK, telegram_id BIGINT, channel TEXT NOT NULL, text TEXT, timestamp TIMESTAMPTZ NOT NULL, views INTEGER, raw_data JSONB, created_at TIMESTAMPTZ DEFAULT NOW()
       - vessel_positions: id BIGSERIAL PK, mmsi INTEGER NOT NULL, ship_name TEXT, latitude FLOAT NOT NULL, longitude FLOAT NOT NULL, speed FLOAT, course FLOAT, timestamp TIMESTAMPTZ NOT NULL, created_at TIMESTAMPTZ DEFAULT NOW()
       - narrative_events: id BIGSERIAL PK, event_type TEXT NOT NULL, summary TEXT NOT NULL, confidence FLOAT, source_ids JSONB, detected_at TIMESTAMPTZ DEFAULT NOW()
       - movement_events: id BIGSERIAL PK, event_type TEXT NOT NULL, vessel_mmsi INTEGER, location_lat FLOAT, location_lon FLOAT, description TEXT, detected_at TIMESTAMPTZ DEFAULT NOW()
       - alerts: id BIGSERIAL PK, severity TEXT NOT NULL CHECK (severity IN ('low','medium','high','critical')), title TEXT NOT NULL, description TEXT, event_ids JSONB, created_at TIMESTAMPTZ DEFAULT NOW(), resolved_at TIMESTAMPTZ
       - briefs: id BIGSERIAL PK, title TEXT NOT NULL, summary TEXT NOT NULL, key_developments JSONB, generated_at TIMESTAMPTZ DEFAULT NOW()

       After table creation, add all 7 tables to supabase_realtime publication:
       ALTER PUBLICATION supabase_realtime ADD TABLE articles, social_posts, vessel_positions, narrative_events, movement_events, alerts, briefs;

       Add indexes for common query patterns:
       - articles: INDEX on (domain, published_at)
       - social_posts: INDEX on (channel, timestamp)
       - vessel_positions: INDEX on (mmsi, timestamp)
       - alerts: INDEX on (severity, created_at)
  </action>
  <verify>
    - Confirm pyproject.toml is valid: `python -c "import tomllib; tomllib.load(open('pyproject.toml', 'rb'))"`
    - Confirm SQL file parses without syntax issues (visual check for balanced parens, semicolons)
    - Confirm all directories exist: `ls src/models/ src/database/ src/fetchers/ supabase/migrations/`
  </verify>
  <done>
    pyproject.toml exists with all dependencies. SQL migration creates 7 tables with realtime publication and indexes. Project directory structure matches research architecture.
  </done>
</task>

<task type="auto">
  <name>Task 2: Pydantic models and async Supabase client</name>
  <files>
    src/models/schemas.py
    src/database/client.py
  </files>
  <action>
    Create Pydantic validation models and the async Supabase client singleton.

    1. Create `src/models/schemas.py` with Pydantic v2 models matching ALL SQL table columns:
       - ArticleCreate(BaseModel): url (str), title (str), domain (str), published_at (datetime), tone_score (float | None), language (str | None), source_country (str | None), raw_data (dict | None)
       - ArticleRow(ArticleCreate): id (int), created_at (datetime) -- represents DB row with generated fields
       - SocialPostCreate(BaseModel): telegram_id (int | None), channel (str), text (str | None), timestamp (datetime), views (int | None), raw_data (dict | None)
       - SocialPostRow(SocialPostCreate): id (int), created_at (datetime)
       - VesselPositionCreate(BaseModel): mmsi (int), ship_name (str | None), latitude (float), longitude (float), speed (float | None), course (float | None), timestamp (datetime)
       - VesselPositionRow(VesselPositionCreate): id (int), created_at (datetime)
       - NarrativeEventCreate(BaseModel): event_type (str), summary (str), confidence (float | None), source_ids (list | None)
       - NarrativeEventRow(NarrativeEventCreate): id (int), detected_at (datetime)
       - MovementEventCreate(BaseModel): event_type (str), vessel_mmsi (int | None), location_lat (float | None), location_lon (float | None), description (str | None)
       - MovementEventRow(MovementEventCreate): id (int), detected_at (datetime)
       - AlertCreate(BaseModel): severity (Literal['low','medium','high','critical']), title (str), description (str | None), event_ids (list | None)
       - AlertRow(AlertCreate): id (int), created_at (datetime), resolved_at (datetime | None)
       - BriefCreate(BaseModel): title (str), summary (str), key_developments (list | None)
       - BriefRow(BriefCreate): id (int), generated_at (datetime)

       Use `model_config = ConfigDict(from_attributes=True)` on all Row models.

    2. Create `src/database/client.py` with async Supabase singleton:
       - Import `acreate_client, AsyncClient` from supabase
       - Import `load_dotenv` from dotenv, call at module level
       - Module-level `_client: AsyncClient | None = None`
       - `async def get_supabase() -> AsyncClient`: returns singleton, creates via acreate_client on first call using SUPABASE_URL and SUPABASE_KEY env vars
       - `async def close_supabase()`: sets _client to None (for clean shutdown)
       - Add error handling: raise ValueError if env vars missing

    IMPORTANT: Use `acreate_client()` not `create_client()` -- sync client does NOT support realtime. This is the most critical pattern from the research.
  </action>
  <verify>
    - Install dependencies: `pip install -e .` (or `pip install supabase pydantic python-dotenv`)
    - Validate models: `python -c "from src.models.schemas import ArticleCreate, VesselPositionCreate; print('Models OK')"`
    - Validate client module imports: `python -c "from src.database.client import get_supabase; print('Client OK')"`
  </verify>
  <done>
    All 14 Pydantic models (7 Create + 7 Row) validate correctly. Async Supabase client singleton uses acreate_client(). Both modules import without errors.
  </done>
</task>

</tasks>

<verification>
1. `ls src/models/schemas.py src/database/client.py supabase/migrations/00001_create_foundation_tables.sql pyproject.toml .env.example .gitignore` -- all files exist
2. `python -c "from src.models.schemas import ArticleCreate, SocialPostCreate, VesselPositionCreate, AlertCreate, BriefCreate; print('All models import OK')"` -- passes
3. `python -c "from src.database.client import get_supabase; print('Client imports OK')"` -- passes
4. SQL migration file contains CREATE TABLE for all 7 tables and ALTER PUBLICATION for realtime
</verification>

<success_criteria>
- Python project installable with `pip install -e .`
- 7 SQL table definitions with realtime publication in single migration file
- 14 Pydantic models (Create + Row variants for all 7 tables)
- Async Supabase client singleton using acreate_client()
- .env.example documents all required API keys
- .gitignore covers Python + Telethon + env files
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md`
</output>
